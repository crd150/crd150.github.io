---
title: "Lab 2: Working with the U.S. Census"
subtitle: <h4 style="font-style:normal">CRD 150 - Quantitative Methods in Community Research</h4>
author: <h4 style="font-style:normal">Professor Noli Brazil</h4>
date: <h4 style="font-style:normal">January 17, 2020</h4>
output: 
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
    theme: cosmo
    code_folding: show
---


<style>
p.comment {
background-color: #DBDBDB;
padding: 10px;
border: 1px solid black;
margin-left: 25px;
border-radius: 5px;
font-style: italic;
}

.figure {
   margin-top: 20px;
   margin-bottom: 20px;
}

h1.title {
  font-weight: bold;
  font-family: Arial;  
}

h2.title {
  font-family: Arial;  
}

</style>


<style type="text/css">
#TOC {
  font-size: 13px;
  font-family: Arial;
}
</style>


\

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


In this guide you will learn how to download, clean and manage - a process known as Data Wrangling - United States Census data using R. You will be working with data on U.S. counties. The objectives of the guide are as follows

1. Download Census data using their API
2. Read data into R
3. Learn data wrangling functions

This lab guide follows closely and supplements the material presented in Chapters 3, 8-10, and 14 in the textbook [R for Data Science](http://r4ds.had.co.nz/index.html) (RDS) and the class Handout 2.

<p class="comment", style="font-style:normal">**Assignment 2 is due by 11:59 pm, January 23rd on Canvas.**   See [here](https://crd150.github.io/hw_guidelines.html) for assignment guidelines. You must submit an `.Rmd` file and its associated `.html` file. Name the files: yourLastName_firstInitial_asgn02. For example: brazil_n_asgn02.</p>    


<div style="margin-bottom:25px;">
</div>
## **Open up a R Markdown file**
\

Download the [Lab template](https://raw.githubusercontent.com/crd150/data/master/labtemplate.Rmd) into an appropriate folder on your hard drive (preferably, a folder named 'Lab 2'), open it in R Studio, and type and run your code there.  Change the title ("Lab 2") and insert your name and date. Don't change anything else inside the YAML (the stuff at the top in between the `---`).  Also keep the grey chunk after the YAML. For a rundown on the use of R Markdown in labs, see [Lab 1](https://crd150.github.io/lab1.html).


<div style="margin-bottom:25px;">
</div>
## **Installing Packages**
\

As described in [Lab 1](https://crd150.github.io/lab1.html), many functions are part of packages that are not preinstalled into R.  In Lab 1, for example, we had to install the package **tidyverse**.  In this lab, you'll need to install the package **tidycensus**, which contains all the functions needed to download Census data.  Run the following code to install **tidycensus**.  

```{r message = FALSE, warning = FALSE, eval=FALSE}
install.packages("tidycensus") 
```

Run the above code directly in your console, not in your R Markdown.  You only need to install packages once. Never more.

<div style="margin-bottom:25px;">
</div>
## **Loading Packages**
\

Installing a package does not mean its functions are accessible during a given R session.  As described in [Lab 1](https://crd150.github.io/lab1.html), you'll need to load packages using the function `library()`.  Unlike installing, you need to use `library()` every time you start an R session, so it should be in your R Markdown file. A good practice is to load all the packages you will be using in a given R Markdown at the top of the file.  Let's load the packages we'll be using in this lab.

```{r message = FALSE, warning=FALSE}
library(tidyverse)
library(tidycensus)
```


<div style="margin-bottom:25px;">
</div>
## **Downloading Census Data**
\

One of the first steps in the Data Wrangling process is to acquire and read in data. There are two ways to bring Census data into R: Using the Census API and downloading from an online source.

<div style="margin-bottom:25px;">
</div>
### **Using the Census API**
\

You can bring data directly into R using the [Census Application Program Interface  (API)](https://www.census.gov/data/developers/guidance/api-user-guide.What_is_the_API.html). An API allows for direct requests for data in machine-readable form.  That is, rather than having to navigate to a website using a browser, scroll around to find a dataset, download that dataset once you find it, save that data onto your hard drive, and then bring the data into R, you just tell R to retrieve data directly using one or two lines of code.  

In order to directly download data from the Census API, you need a key.  You can sign up for a free key [here](http://api.census.gov/data/key_signup.html), which you should have already done before the lab. Type your key in quotes using the `census_api_key()` command


```{r include=FALSE, warning=FALSE, results="hide"}
census_api_key("b81d373d6e785ecbc489de1fc862aef424d0a63a")
```

```{r eval=FALSE, warning=FALSE, results="hide"}
census_api_key("YOUR API KEY GOES HERE")
```

The function for downloading American Community Survey (ACS) Census data is `get_acs()`. The command for downloading decennial Census data is `get_decennial()`.  Getting variables using the Census API requires knowing the variable ID - and there are thousands of variables (and thus thousands of IDs) across the different Census files. To rapidly search for variables, use the commands `load_variables()` and `View()`. Because we'll be using the ACS in this guide, let's check the variables in the most recent 5-year ACS (2013-2017) using the following commands.

```{r warning = FALSE}
v17 <- load_variables(2017, "acs5", cache = TRUE)
View(v17)
```

A window should have popped up showing you a record layout of the 2013-17 ACS.  To search for specific data, select "Filter" located at the top left of this window and use the search boxes that pop up.  For example, type in "Hispanic" in the box under "Label".  You should see near the top of the list the first set of variables we'll want to download - race/ethnicity.  Let's extract that data and total population for California counties using the `get_acs()` command

```{r message = FALSE, warning = FALSE}
ca <- get_acs(geography = "county", 
              year = 2017,
              variables = c(tpopr = "B03002_001", 
                            nhwhite = "B03002_003", nhblk = "B03002_004", 
                            nhasn = "B03002_006", hisp = "B03002_012"), 
              state = "CA",
              survey = "acs5")
```

In the above code, we specified the following arguments


* `geography`: The level of geography we want the data in; in our case, the county. Other geographic options can be found [here](https://walkerke.github.io/tidycensus/articles/basic-usage.html#geography-in-tidycensus). 
* `year`: The end year of the data (because we want 2013-2017, we use 2017).
* `variables`: The variables we want to bring in as specified in a vector you create using the function `c()`. Note that we created variable names of our own (e.g. "nhwhite") and we put the ACS IDs in quotes ("B03002_003"). Had we not done this, the variable names will come in as they are named in the ACS, which are not very descriptive.
* `state`: We can filter the counties to those in a specific state.  Here it is "CA" for California.  If we don't specify this, we get all counties in the United States. When we cover Census tracts in the next lab, a `county` filter will also be available.
* `survey`: The specific Census survey were extracting data from.  We want data from the 5-year American Community Survey, so we specify "acs5". The ACS comes in 1-, 3-, and 5-year varieties.  

Type in `? get_acs()` to see the full list of options. 

When you bring in a dataset, the first thing you should always do is view it just to make sure you got what you expected.  You can do this directly in the console by just typing out the file name.

```{r}
ca
```


You should see a tibble pop up with the variables we selected. Take some time to understand the format of the data set. What do the columns represent? Rows? Is *ca* in wide or long format?  

Alternatively, if you like viewing your data through an Excel style worksheet, type in `View(ca)`, and *ca* should pop up in the top left window of your R Studio interface. Scroll up and down, left and right. 


<div style="margin-bottom:25px;">
</div>
### **Downloading from an online source**
\

The other way to get Census data is to download them directly from the web onto your hard drive.  There are several websites where you can download Census data including [Social Explorer](https://www.socialexplorer.com/) and [PolicyMap](https://ucdavis.policymap.com/maps), both of which we have free access to as UC Davis affiliates, and [data.census.gov](https://data.census.gov/cedsci/?intcmp=aff_cedsci_banner), which is free for everyone.  The site we used in lecture is the [National Historical Geographic Information System (NHGIS)](https://www.nhgis.org/).  You may choose to use NHGIS (or any of the other sources listed above) over the API because it is more user friendly in terms of selecting variables.  We went through the NHGIS data downloading process during lecture.  If you need a refresher on the process, I've uploaded a brief step-by-step tutorial [here](http://crd150.github.io/nhgis.html).

To save us time, I've uploaded an NHGIS csv file on GitHub for you to use in this lab. Download the file [here](https://raw.githubusercontent.com/crd150/data/master/nhgis0086_ds225_20165_2016_county.csv) and save it into the same folder where your Lab 2 R Markdown file resides.  This file contains the same data you downloaded during the tutorial in class.  The record layout/codebook for the file can be found [here](https://raw.githubusercontent.com/crd150/data/master/nhgis0086_ds225_20165_2016_county_codebook.txt).  

<div style="margin-bottom:25px;">
</div>
## **Reading in Data**
\

Most of the data files you will encounter are comma-delimited (or comma-separated) files, which have `.csv` extensions.  Comma-delimited means that columns are separated by commas.  The file from NHGIS is a `.csv` file.  To import this file in R, use the `read_csv()` command, which is found in the **tidyverse** package. 

```{r warning=FALSE, results="hide", message=FALSE, echo=FALSE}
nhgisfile1 <- read_csv("https://raw.githubusercontent.com/crd150/data/master/nhgis0086_ds225_20165_2016_county.csv")
```

To read in the csv file you downloaded from NHGIS, first make sure that R is pointed to the folder you saved your data into.  Type in `getwd()` to find out the current directory and `setwd("directory name")` to set the directory to the folder containing the data.  In my Mac OS computer, the NHGIS file is located in the folder shown in Figure 1.

<center>
![Figure 1: Directory path where your data reside reside.](/Users/noli/Documents/UCD/teaching/CRD150/Lab/crd150.github.io/setwd.png)

</center>

Using a Mac laptop, I type in the following command to set the directory to the folder containing my data.

```{r, eval = FALSE}
setwd("/Users/noli/Desktop/Classes/CRD150/Lab 2")
```

For a Windows system, you can find the pathway of a file by right clicking on it and selecting Properties. You will find that instead of a forward slash like in a Mac, a windows pathway will be indicated by a single back slash `\`.  R doesn't like this because it thinks of a single back slash as an [escape character](https://en.wikipedia.org/wiki/Escape_character).  Use instead two back slashes `\\` 

```{r, eval = FALSE}
setwd("C:\\Users\\noli\\Desktop\\Classes\\CRD150\\Lab 2")
```

or a forward slash `/`.  

```{r, eval = FALSE}
setwd("C:/Users/noli/Desktop/Classes/CRD150/Lab 2")
```

You can also manually set the working directory by clicking on Session -> Set Working Directory -> Choose Directory.

<br>

Once you've set your directory, use `read_csv()` and plug in the name of the file in quotes inside the parentheses.  Make sure you include the *.csv* extension.  

```{r, eval = FALSE}
nhgisfile1 <- read_csv("nhgis0083_ds225_20165_2016_county.csv")
```


<div style="margin-bottom:25px;">
</div>
## **More Data Wrangling** 
\


It is rare that the data you download are in exactly the right form for analysis.  For example, rather than all counties in the tibble *ca*, you might want to analyze just Northern California counties. Or you might want to discard certain variables from the dataset to reduce clutter. Or you encounter missing data. 

In this lab, we won't have time to go through all of the methods and functions in R that are associated with the data wrangling process. We will cover more in later labs and many methods you will have to learn on your own given the specific tasks you will need to accomplish.  In the rest of this guide, we'll go through some of the basic data wrangling techniques using the functions found in the package **dplyr**, which was automatically installed and loaded when you brought in the **tidyverse** package.  These functions can be used for tibbles and regular data frames.

<div style="margin-bottom:25px;">
</div>
### **Selecting and renaming variables**
\

In practice, most of the data files you will download will contain variables you won't need. It is easier to work with a smaller dataset as it reduces clutter and clears up memory space, which is important if you are executing complex tasks on a large number of observations.  Use the command `select()` to keep variables by name.  Visually, we are doing this (taken from the RStudio [cheatsheet](http://www.rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf))  

<center>
![](/Users/noli/Documents/UCD/teaching/CRD150/Lab/crd150.github.io/subsetcols.png)

</center>


To see the names of variables in the dataset *ca*, use the `names()` command.  

```{r}
names(ca)
```

Let's keep *GEOID*, *NAME*, *variable*, and *estimate* from the *ca* dataset.

```{r}
select(ca, GEOID, NAME, variable, estimate)
```

A shortcut way of doing this is to use the `:` operator.  

```{r}
select(ca, GEOID:estimate)
```

The `:` operator tells R to select all the variables from *GEOID* to *estimate*.  This operator is useful when you've got a lot of variables to keep and they all happen to be ordered sequentially.

You can use the `select()` command to keep variables *except* for the ones you designate.  For example, to keep all variables in *ca* except *moe*, which represents the [margin of error](https://walkerke.github.io/tidycensus/articles/margins-of-error.html), an important value but something we don't need for the purposes of this exercise, and save this into a new tibble called *ca1*, type in

```{r, results="hide"}
ca1 <- select(ca, -moe)
```

The negative sign tells R to exclude the variable named right after. You can delete multiple variables.  For example, let's eliminate all the margin of error variables in the *nhgisfile1* data frame.  These variables are sequentially located at the end of the data set, so we can use the colon `:` operator.

```{r}
nhgisfile1 <- select(nhgisfile1, -(NAME_M:AF4OM025))
```

<br>

You will likely encounter a variable with a name that is not descriptive. Although you should have a codebook to crosswalk variable names with descriptions, the more descriptive the names, the more efficient your analysis will be and the less likely you are going to make a mistake. Use the command `rename()` to - what else? - rename a variable!  Let's rename the variable *NAME* to *County* in the *ca* dataset.  Make this permanent by assigning it back to *ca1* using the arrow operator `<-`

```{r}
ca1 <- rename(ca1, County = NAME)
names(ca1)
```

<br>

Note that you can rename multiple variables within the same `rename()` command, separating each `newvariablename` = `oldvariablename` argument with a comma. For example, `rename(ca1, newvariablename1 = oldvariablename1,` `newvariablename2 = oldvariablename2)`.  Also note that if your variable name has spaces in between words, R will despise you.  To make it happy, you'll have to put the variable name in quotes, like `newvariablename =` `"old variable name"`.  I recommend **never!** including spaces in your variable names. Use an underline or even a period instead if you really want to separate words.


<div style="margin-bottom:25px;">
</div>                            
### **Reshape the data**
\

Tidying up a dataset for your specific data project means following the rules outlined on page 149 of RDS: (1) Each variable must have its own column, (2) each observation must have its own row, and (3) each value must have its own cell. For the purposes of this lab, our tidy dataset should have counties as the unit of observations. The dataset *nhgisfile1* looks "tidy", but the dataset *ca1* is not.  Why?

We'll need to "spread" or reshape the dataset to get it to the form we want. This will convert the dataset from long to wide.  Use the function `spread()` and save the tidy dataset back into *cacounty*. 

```{r}
ca1 <- spread(ca1, key = variable, value = estimate)
ca1
```

Compare *ca1* and *ca*.  *ca* is a county by variable dataset whereas *ca1* is a county dataset.  

Note that you can get a wide data frame directly from the `get_acs()` function using the argument `output = "wide"`. As an exercise on your own, add this argument to the `get_acs()` code way above that created *ca* and see what you get.


<div style="margin-bottom:25px;">
</div>
### **Merging files**
\

Our next goal is to merge together the datasets *nhgisfile1* and *ca1*.  Handout 2 (pg. 7 and Figure 5) describes the process of merging datasets. Remember from lecture that the unique Census ID for a county combines the county ID with the state ID.  We have this ID as the single variable GEOID in *ca1*, but separated as *STATEA* and *COUNTYA* in nhgisfile1.  See Figure 2.

<center>
![Figure 2: Geographic IDs](/Users/noli/Documents/UCD/teaching/CRD150/Lab/crd150.github.io/fig2.png)

</center>


We can merge the two files by either merging on a single variable or on the two separate variables.  We just need to make sure it is consistent across the two datasets.  Let's combine *STATEA* and *COUNTYA* into a single variable so it will match *GEOID*.  To do this, use the command `str_c()` in the `mutate()` command.  The function `str_c()` concatenates (joins together) two or more character variables.  

```{r}
nhgisfile1 <- mutate(nhgisfile1, GEOID = str_c(STATEA, COUNTYA))
```

In the above code, we used the function `mutate()` to create a new variable *GEOID* in the tibble *nhgisfile1* that concatenates the variables *STATEA* and *COUNTYA*. Check *nhgisfile1* in your console or data view to see if we got what we needed.  We'll go through the `mutate()` function a bit more in the next section.


To merge the two datasets together, use the function `left_join()`, which matches pairs of observations whenever their keys or IDs are equal. We match on the variable *GEOID* and save the merged data set into a new object called *cacounty*.

```{r}
cacounty <- left_join(ca1, nhgisfile1, by = "GEOID")
```

The code above tells R to join all the variables in *nhgisfile1* to *cal1* using the ID *GEOID* to match rows.  

The resulting join merges the variables from *nhgisfile1* **into** *ca1*. As such, *cacounty* should only contain California counties.  All the other counties in *nhgisfile1* are not included - remember, `left_join()` is joining columns not rows. You can check this by examining the dimensions of *ca1*, *cacounty* and *nhgisfile1*.

```{r}
dim(cacounty)
dim(ca1)
dim(nhgisfile1)
```

The number of rows in *ca1* and *cacounty* are equal.  The number of columns in *cacounty* equals the number of columns in *ca1* plus the number of columns in *nhgisfile1* minus the ID variable you merged on.

Note that if you have two variables with the same name in both files, R will attach a *.x* to the variable name in *ca1* and a *.y* to the variable name in *nhgisfile1*.  For example, if you have a variable named *Jake* in both files, *cacounty* will contain both variables and name it *Jake.x* (the variable in *ca1*) and *Jake.y* (the variable in *nhgisfile1*).  Try to avoid having variables with the same names in the two files you want to merge. 

There are other types of joins, which you can read more about in Chapter 10 of RDS.

   
<div style="margin-bottom:25px;">
</div>
### **Creating new variables**
\

The `mutate()` function allows you to create new variables within your dataset.  This is important when you need to transform variables in some way - for example, calculating a ratio or adding two variables together.  We already covered this command above to create *GEOID* in the *nhgisfile1* object.  Visually, you are doing this

<center>
![](/Users/noli/Documents/UCD/teaching/CRD150/Lab/crd150.github.io/mutate.png)

</center>

You can use the `mutate()` command to generate as many new variables as you would like.  For example, let's construct five new variables in *cacounty*: the proportion of residents who are non-Hispanic white, non-Hispanic Asian, non-Hispanic black, Hispanic, and who have a bachelors degree or higher. Name these variables *pnhwhite*, *pnhasn*, *pnhblk*, *phisp*, and *pcol*, respectively.

```{r, results="hide"}
mutate(cacounty, pnhwhite = nhwhite/tpopr, pnhasn = nhasn/tpopr, 
              pnhblk = nhblk/tpopr, phisp = hisp/tpopr,
              pcol = (AF4OE022+AF4OE023+AF4OE024+AF4OE025)/AF4OE001)
```
  
Note that you can create new variables based on the variables you just created in the same line of code (Wow!). For example, you can create a variable named *diff* that represents the difference between the percent non-Hispanic white and percent non-Hispanic black after creating both variables within the same `mutate()` command. Letâ€™s save these changes back into *ca1.*

```{r, results="hide"}
cacounty <- mutate(cacounty, pnhwhite = nhwhite/tpopr, pnhasn = nhasn/tpopr, 
              pnhblk = nhblk/tpopr, phisp = hisp/tpopr,
              pcol = (AF4OE022+AF4OE023+AF4OE024+AF4OE025)/AF4OE001,
              diff = pnhwhite-phisp)
```

View *cacounty* to verify that you've successfully created these variables.

<div style="margin-bottom:25px;">
</div>
### **Pipes**
\

One of the important innovations from the tidy verse is the pipe operator `%>%`.  You use the pipe operator when you want to combine multiple operations into one line of code.  For example, we can use a pipe to combine all the commands we executed on the object *ca* from the sections *Selecting and renaming variables* to *Creating new variables* in one continuous line of code.

```{r eval = FALSE}
cacounty2 <- ca %>% 
      select(-moe) %>% 
      rename(County = NAME) %>%
      spread(key = variable, value = estimate) %>%
      left_join(nhgisfile1, by = "GEOID") %>%
      mutate(pnhwhite = nhwhite/tpopr, pnhasn = nhasn/tpopr, 
              pnhblk = nhblk/tpopr, phisp = hisp/tpopr,
              pcol = (AF4OE022+AF4OE023+AF4OE024+AF4OE025)/AF4OE001,
              diff = pnhwhite-phisp)
```

<br>

Let's break down what the pipe is doing here.  First, you start out with your dataset *ca*.  You "pipe" that into the command `select()`.  Notice that you didn't have to type in *ca* inside the `select()` command - `%>%` pipes that in for you.  `select()` deletes *moe* and then pipes this result into the command `rename()`, which renames *NAME* into *County*. The resulting object then gets piped to the command `spread()` to reshape it into wide format. This reshaped dataframe gets piped to `left_join()` to merge in *nhgisfile1*, which gets piped to `mutate()` to create new variables. Finally, the code saves the result into *cacounty2* which we designated at the beginning with the arrow operator. *cacounty2* should be exactly the same as *cacounty*, which we created using the same code, but using multiple lines of separated code.

The pipe operator is very useful for complex operations, which you will encounter in the coming weeks.  From now on, we'll be using the pipe operator to make our code more efficient, so make sure you understand what pipes are doing.

<div style="margin-bottom:25px;">
</div>
### **Subsetting/Filtering**
\

Subsetting or filtering means selecting rows/observations based on their values.  To subset in R, use the command `filter()`.  Visually, subsetting rows looks like this.

<center>
![](/Users/noli/Documents/UCD/teaching/CRD150/Lab/crd150.github.io/subsetrows.png)

</center>

The first argument in the parentheses of this command is the name of the data frame. The second and any subsequent arguments (separated by commas) are the expressions that filter the data frame. For example, we can keep just Sacramento county from *cacounty* using its [FIPS code](https://www.nrcs.usda.gov/wps/portal/nrcs/detail/ca/home/?cid=nrcs143_013697)

```{r, results="hide"}
filter(cacounty, GEOID == "06067")
```

The double equal operator `==` means equal to.  The command is telling R to keep the rows in *cacounty* whose *GEOID* equals "06067".  There are quotes around 06067 because *GEOID* is a character variable.  

We can also explicitly exclude cases and keep everything else by using the not equal operator `!=`.  The following code *excludes* Sacramento county.

```{r, results="hide"}
filter(cacounty, GEOID != "06067")
```


What about filtering if a county has a value greater than a specified value?  For example, counties with a percent Hispanic greater than 0.5 (50%). 

```{r, results="hide"}
filter(cacounty, phisp > 0.50)
```

What about less than 0.5 (50%)?

```{r, results="hide"}
filter(cacounty, phisp < 0.50)
```

Both lines of code do not include counties that have a percent Hispanic equal to 0.5.  We include it by using the less than or equal operator `<=` or greater than or equal operator `>=`.

```{r, results="hide"}
filter(cacounty, phisp <= 0.5)
```

In addition to comparison operators, subsetting may also utilize logical operators that make multiple selections.  There are three basic logical operators: `&` (and), `|` (or), and `!` (not).  We can keep counties with *phisp* greater than 0.5 **and** *pcol* greater than 0.15 by using `&`.

```{r, results="hide"}
filter(cacounty, phisp > 0.5 & pcol > 0.15)
```

Use `|` to keep counties with a *GEOID* of "06067" (Sacramento) **or** "06113" (Yolo) 

```{r, results="hide"}
filter(cacounty, GEOID == "06067" | GEOID == "06113")
```

<div style="margin-bottom:25px;">
</div>
### **Missing Data**
\

A special value used across all data types is `NA`. The value `NA` indicates a missing value (stands for "Not Available").  Properly treating missing values is very important. The first question to ask when they appear is whether they should be missing. Or did you make a mistake in the data wrangling? If so, fix the mistake, dude. If they should be missing, the second question becomes how to treat them. Can they be ignored? Should the records with NAs be removed?  

Numerics also use other special values to handle problematic values after division.  R spits out `-Inf` and `Inf` when dividing a negative and positive value by 0, respectively, and `NaN` when dividing 0 by 0.

```{r, error=TRUE}
-1/0
1/0
0/0
```

You will likely encounter `NA`, `Inf`, and `NaN` values, even in already relatively clean datasets like those produced by the Census. We will cover R functions that deal with missingness in Lab 3.


<div style="margin-bottom:25px;">
</div>
## **Saving Data**
\

Let's save a dataset containing race/ethnicity and percent college graduates for all 58 counties in California. You'll be using this file in Assignment 2. First, we use `select()` to select the variables.

```{r}
cacounty <- select(cacounty, County, GEOID, pcol, pnhwhite:phisp)
```

Then we use `write_csv()` to save the data frame or tibble as a csv file in the folder of your current working directory.

```{r eval = FALSE}
write_csv(cacounty, "lab2_file.csv")
```

The first argument is the name of the R object you want to save. The second argument is the name of the csv file in quotes. Make sure to add the .csv extension. The file is saved in the folder you set as the current working directory (remember, use `getwd()` to determine the current directory). You're done! [Time to celebrate](https://www.youtube.com/watch?v=3GwjfUFyY6M).


***


<a rel="license" href="http://creativecommons.org/licenses/by-nc/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc/4.0/88x31.png" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nc/4.0/">Creative Commons Attribution-NonCommercial 4.0 International License</a>.


Website created and maintained by [Noli Brazil](https://nbrazil.faculty.ucdavis.edu/)